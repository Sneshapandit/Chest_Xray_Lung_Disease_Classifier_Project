import os
import numpy as np
import tensorflow as tf
import pickle
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score, classification_report
import logging

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Directory paths
PROJECT_ROOT = os.path.abspath(os.path.dirname(__file__))
preferred_processed = os.path.join(PROJECT_ROOT, "data", "processed", "densenet")
legacy_processed = os.path.join(PROJECT_ROOT, "processed_data-20260212T135828Z-1-001", "processed_data", "densenet")
output_dir = preferred_processed if os.path.isdir(preferred_processed) else legacy_processed
train_test_split_path = os.path.join(output_dir, "train_test_split")

# Check if dataset files exist
if not (os.path.exists(os.path.join(train_test_split_path, "X_test.npy")) and os.path.exists(os.path.join(train_test_split_path, "y_test.npy"))):
    logging.error("Test dataset files not found. Exiting.")
    exit()

# Load test dataset
X_test = np.load(os.path.join(train_test_split_path, "X_test.npy"))
y_test = np.load(os.path.join(train_test_split_path, "y_test.npy"))

# Check if DenseNet model exists
densenet_model_path = os.path.join(output_dir, "densenet_feature_extractor.keras")
if not os.path.exists(densenet_model_path):
    logging.error("DenseNet121 feature extractor model file not found. Exiting.")
    exit()

# Load DenseNet121 feature extractor model
try:
    feature_extractor = tf.keras.models.load_model(densenet_model_path)
    logging.info("Loaded DenseNet121 feature extractor model.")
except Exception as e:
    logging.error(f"Failed to load DenseNet121 model: {e}")
    exit()

# Extract features from test images
test_features = feature_extractor.predict(X_test, verbose=1)
logging.info(f"Extracted test features shape: {test_features.shape}")

# Check if PCA model exists
pca_path = os.path.join(output_dir, "pca_model.pkl")
if not os.path.exists(pca_path):
    logging.error("PCA model file not found. Exiting.")
    exit()

# Load PCA model
try:
    with open(pca_path, 'rb') as f:
        pca_data = pickle.load(f)
    pca = PCA(n_components=100)
    pca.components_ = pca_data['components']
    pca.explained_variance_ = pca_data['explained_variance']
    pca.mean_ = pca_data['mean']
    logging.info("Loaded PCA model.")
except Exception as e:
    logging.error(f"Failed to load PCA model: {e}")
    exit()

# Transform test features using PCA
test_features_reduced = pca.transform(test_features)
logging.info(f"Transformed test features shape: {test_features_reduced.shape}")

# Check if classifier model exists
classifier_model_path = os.path.join(output_dir, "classifier_model.keras")
if not os.path.exists(classifier_model_path):
    logging.error("Classifier model file not found. Exiting.")
    exit()

# Load trained classifier model
try:
    classifier = tf.keras.models.load_model(classifier_model_path)
    logging.info("Loaded trained classifier model.")
except Exception as e:
    logging.error(f"Failed to load classifier model: {e}")
    exit()

# Predict test labels
y_pred = np.argmax(classifier.predict(test_features_reduced), axis=1)

# Compute accuracy
accuracy = accuracy_score(y_test, y_pred)
logging.info(f"Testing Accuracy: {accuracy:.4f}")

# Generate classification report
class_report = classification_report(y_test, y_pred)
logging.info("Classification Report:\n" + class_report)

print(f"Testing Accuracy: {accuracy:.4f}")
print("Classification Report:\n", class_report)